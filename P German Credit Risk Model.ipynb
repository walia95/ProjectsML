{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This project is a classification project, where we will be classifying customers based on their data if a loan can be approved for them.\n",
    "\n",
    "## Here the false negative rate should be very low.As the customers wrongly classified as low risk could be bad for business.\n",
    "\n",
    "* Since we have an imbalanced dataset, we will be using data balancing techniques such as oversampling, undersampling , SMOTE etc.\n",
    "* We have 20 input variables, where we have 7 numerical  and 13 are categorical.\n",
    "* We will be adding penalties for mis classifications. Where the False Negatives will be charged 5 whereas the cost of False Positive would be 1.\n",
    "* Since we also have categorical values, we will be using one-hot encoding.\n",
    "* The numerical variables have a different scale, so scaling would be required for the algorithms which are sensitive to scale.\n",
    "* In the last column we have the classifications for positive and negative classes as 1 and 2, we will convert them to 0 and 1.\n",
    "* In scenarios where False negatives are more dangerous, we want higher recall scores.Recall is the percentage of the total correct percentage of the releavent results classified by the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'german.csv'\n",
    "dataframe = read_csv(filename,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2    3     4    5    6   7    8     9   ...    11  12    13  \\\n",
       "0  A11   6  A34  A43  1169  A65  A75   4  A93  A101  ...  A121  67  A143   \n",
       "1  A12  48  A32  A43  5951  A61  A73   2  A92  A101  ...  A121  22  A143   \n",
       "2  A14  12  A34  A46  2096  A61  A74   2  A93  A101  ...  A121  49  A143   \n",
       "3  A11  42  A32  A42  7882  A61  A74   2  A93  A103  ...  A122  45  A143   \n",
       "4  A11  24  A33  A40  4870  A61  A73   3  A93  A101  ...  A124  53  A143   \n",
       "\n",
       "     14 15    16 17    18    19 20  \n",
       "0  A152  2  A173  1  A192  A201  1  \n",
       "1  A152  1  A173  1  A191  A201  2  \n",
       "2  A152  1  A172  2  A191  A201  1  \n",
       "3  A153  1  A173  2  A191  A201  1  \n",
       "4  A153  2  A173  2  A191  A201  2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.155000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>0.458487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1             4            7            10           12  \\\n",
       "count  1000.000000   1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     20.903000   3271.258000     2.973000     2.845000    35.546000   \n",
       "std      12.058814   2822.736876     1.118715     1.103718    11.375469   \n",
       "min       4.000000    250.000000     1.000000     1.000000    19.000000   \n",
       "25%      12.000000   1365.500000     2.000000     2.000000    27.000000   \n",
       "50%      18.000000   2319.500000     3.000000     3.000000    33.000000   \n",
       "75%      24.000000   3972.250000     4.000000     4.000000    42.000000   \n",
       "max      72.000000  18424.000000     4.000000     4.000000    75.000000   \n",
       "\n",
       "                15           17           20  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      1.407000     1.155000     1.300000  \n",
       "std       0.577654     0.362086     0.458487  \n",
       "min       1.000000     1.000000     1.000000  \n",
       "25%       1.000000     1.000000     1.000000  \n",
       "50%       1.000000     1.000000     1.000000  \n",
       "75%       2.000000     1.000000     2.000000  \n",
       "max       4.000000     2.000000     2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, Count=700, Percentage=70.000%\n",
      "Class=2, Count=300, Percentage=30.000%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "target=dataframe.values[:,-1]\n",
    "counter = Counter(target)\n",
    "for k, v in counter.items():\n",
    "    per = v/len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k,v,per))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD7CAYAAABUt054AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO40lEQVR4nO3dX4xc513G8eeJXbC1rpHohhVthVcqYCA1pewiqiLalRqpripuGi6QjJK9QEYgS1wYkC/a1CERyo1vaCqQpcCmxRIikIJQVKHS7qDkpmIX1ESWnIuSLYWSgkG4mU0bcPhxsbPRsJ3/55z5nXPm+5FG8s6Z3fM7fneefc8757yvI0IAgPm7J7sAAFhUBDAAJCGAASAJAQwASQhgAEhCAANAEgIYAJK0OoBtX7K9Y/t121vZ9aA6tn/E9nds/3F2LSiP7e6Rxxu2P5VdV1mOZxdQsW9IekzShyWdTK4F1fq0pL/LLgLliohTh/+2vSTpm5KezquoXK3uAUfEMxHxF5L+I7sWVMf2L0n6L0lfzK4FlfpFSf8m6bnsQsrS6gBG+9k+Lel3JF3OrgWVe0jSZ6JF8ycQwGi6RyU9GRFfzy4E1bH9Q5I+KOmp7FrK1PYxYLSY7Z+SdL+k92bXgso9KOn5iHg5u5AyEcBosg1Jq5L+ybYknZJ0zPZPRMRPJ9aF8j0o6fHsIsrW6gC2fVwHx3hMB2/ME5LuRsTd3MpQkuuS/qTv69/UQSD/Wko1qITt90t6h1p09cOhto8Bf1zStyVdkfTLvX9/PLUilCYiXouIVw4fkrqSvhMR/55dG0r1kKRnIuLV7ELK5hZ9oAgAjdL2HjAA1BYBDABJCGAASEIAA0ASAhgAkkx1HfDy8nKsrq5WVMpw+/v7Wlpamvt+67DvW7du3Y6Ie+e1z/42zjz2IppW9+7ublobZ2ha+0xr0PENbeOImPixtrYWGba3t1P2W4d9S9qJKdqo6KO/jTOPvYim1Z3Zxhma1j7TGnR8w9qYIQgASJJ+K/LqlWdHbt97/KNzqgSD0D7A/zfuPbF1fvLhFXrAAJCEAAaAJAQwACQhgAEgCQEMAEnSr4JAPtsXJV2UpJWVFXU6HUlSt9vV5XNvjPzew9fWSbfbrWVdwFEEMBQR13WwuoTW19djY2ND0kG4Xnt+f+T37l3YqLi66XU6HR0eA1BnDEEAQBJ6wMACGDbMlKHpQ0SXz41eUnKa4yOAgQUwbJgpQ9OHiDYnuBNu0uNjCAIAkhDAAJCk0iGIcZNWAMAiowcMAEkIYABIQgADQBICGACSEMAAkIQbMVDIJFe6sGwRMBg9YABIQgADQBICGACSjB0DLjKL0rhZgybR6XRSZ0/K3jeA9hobwEVmURo3a9Ak9i5spM6elL1vAO3FEAQAJCGAASAJAQwASQrdiMF0kwAwO+6EA1C5/s7a5XN3B35Av4h3TDIEAQBJ6AFj6LXe3W5Xl8+9Ufjnz/tyuqavuovFQQBj6LXenU5H157fL/zz9y5sFP4Z02j6qrtYHAQwsACK3NFahv67YldODr5LtilnLePu8J3mDIwABhZAkTtay7B55EO4ay9+d/TM+0xpVuPu8N06vzTxGRgfwgFAEgIYAJIQwACQhDFgAK3QxOWx6AEDQBICGACSMAQBLLhxp+51O21vE3rAAJCkFT1g/oIDaCJ6wACQpBU9YNQbZyjAYPSAASAJPWCka+IF9EAZah/Aq1eeHbqESdn7GeRw3wQAgLIxBAEASQhgAEhCAANAktqPAQMSl7KhnegBA0CShegBT3KZEwDM20IE8Lxwmpxn9ciij7Nctkj7YN4IYKCHP6CYN0fE6BfYFyVd7H15VtJLVRc1wLKk2wn7rcO+lyLi3ip3MqKNM4+9iKbVfSaxjTM0rX2mNej4Brbx2ACuA9s7EbHOvhdr/7Nqat2Lou3tM83xcRUEACQhgAEgSVMC+PokL7J9yfaO7ddtbx3Z9iHbt2y/Znvb9pky912RzH3XYf/fZVgb236f7S/Y/k9JZ20/bfsH8yrFCCN/r0a08artsN3te3yi8mqnN/H7phFjwJOy/TFJ/yvpw5JORsRm7/llSV+V9CuS/krSo5J+PiLel1QqZjSijT8i6ZSkv5Z0V9ITkt4eEeeTSsWMRrTxqqSXJb0lIu5m1VemVl2GFhHPSJLtdUnv7Nv0MUk3I+Lp3varkm7b/rGIuDX3QjGzYW0cEZ/vf53tJyT97XyrQxlGvI9bpylDEEXdJ+krh19ExL4OesT3pVWEqn1A0s3sIlCJr9n+Z9t/1Du7baxFCeBTku4cee6OpLcm1IKK2f5JSQ9L+q3sWlCq25J+RtIZSWs6eP/eSK2ooFYNQYzQlXT6yHOnJb2aUAsqZPuHJX1e0m9ExHPZ9aA8EdGVtNP78pu2L0n6V9unI+JbiaXNbFF6wDclvefwC9tLkt4lTlFbpXdly99IejQiPptdDyp3eAWBU6sooFUBbPu47ROSjkk6ZvuE7eOSPifp3bYf6G1/WNILfADXPMPa2PY7JH1J0qcj4g9yq0QRI9r4Z22ftX2P7bdJ+j1JnYg4OrzYGG27DO2qpE8eefqRiLhq+34dXJp0RtKXJW1GxN58K0RRw9pYB72hq5L2+zdExKm5FIbSjGjjlyT9rqQfkPQtSV+Q9NsR8cpcCyxRqwIYAJqkVUMQANAkBDAAJCGAASAJAQwASaa6EWN5eTlWV1crKmW8/f19LS0tpe2/aoOOb3d393bVqyX0m6WN69oudayrqW1cpjq2S5mmauOImPixtrYWmba3t1P3X7VBxydpJ6Zoo6KPWdq4ru1Sx7qa2sZlqmO7lGmaNmYIAgCSLMpcELUwbtXdrfPNOy1bvfLs2GXgWU243lgNOg89YABIMrYH3L+c9crKijqdTtU1DdXtdlP3X9Tlc6Mn8W/68QGYztgAjojr6q1xtL6+HhsbG1XXNFSn01Hm/osadZouHQxBNPn4AEyHIQgASEIAA0ASAhgAkhDAAJCEAAaAJAQwACQhgAEgCQEMAEmYCwJYAKPuaB13h2bZd2e2/Y7PaY6PAAYWwKg7Wsfdobl3YWPk9mk1/Y7WcaY5PgIYheb7uHzurlZOju5FZfV26tjTqmNNyFP7AO6fKm/YtIdMl1dMkfk+NnvTUV57cfivUtk9qEnVsadVx5qQhw/hACAJAQwASQhgAEhS+zFgNB9L3gCD0QMGgCQEMAAkIYABIAkBDABJ+BAO6cZ9SCfxQR3aiQDGSJOEI4DZMAQBAEkIYABIwhAEgMoxqdZg9IABIMnYHnCRuWLL0D/P7LB5Z5syv+q4lQeYKxZYLGMDuMhcsWXYPHLqMmje2az5Zqc1buWBrfNLzBULLBCGIAAgCQEMAEkIYABIwmVowALIXpa+TR+mj8Oy9JhKkTenNPwNVaZZ3px1vKokq6bsZenb9GH6OCxLP4NFXrWhyJtTGv6GKtMsb846rkBcx5qQhwBGIyzyH0i0Fx/CAUCSQj1geiUAMDt6wACQhDFgtMKgs7Gjs25xRoa6oQcMAEkIYABIQgADQBICGACSEMAAkIQABoAkXIaGhcGNQ6gbesAAkIQABoAkDEEAPQxRYN4IYGBC4wJaIqQxHYYgACAJPWAArdDEMxQCGCjRuBDYOr80p0rQBAQwAEyhzD+yjojRL+hbMVfSWUkvTfzTy7cs6Xbi/qs26PjORMS9Ve60hDaua7vUsa6mtnGZ6tguZZq4jccGcJ3Y3omI9ew6qtLU46tr3XWsq441zVvb/w+mOT6uggCAJK0KYNuXbO/Yft32Vt/zF2x3+x6v2Q7ba4nlYkq2v9f2k7a/ZvtV2/9g+yN92z9k+1avfbclfU9iucBYTQvg62O2f0PSY5L+sP/JiLgREacOH5J+XdI/Svr7asqc2bjjq6t51X1c0tclfVDS90n6hKQ/tb1qe1nSM73nvl/SjqRTc6prGk1t4zK1/f9g4uNr1BjwpGw/JumdEbE5ZPu2pE5EPDLXwlA62y9IekTS2yRtRsT7e88v6eCDkPdGxK3EEoGhmtYDLsz2GUkfkPSZ7FpQjO0VST8q6aak+yR95XBbROxL+mrveaCWFi6AJT0o6bmIeDm7EMzO9lsk3ZD0VK+He0rSnSMvuyPprfOuDZjUogbwU9lFYHa275H0WUn/LelS7+mupNNHXnpa0qtzLA2YykIFsO2fk/R2SX+WXQtmY9uSnpS0IumBiPif3qabkt7T97olSe/qPQ/UUqsC2PZx2yckHZN0zPYJ2/23Wz8k6c8jgl5Rc/2+pB+X9AsR8e2+5z8n6d22H+j9Djws6QU+gEOdteoqCNtXJX3yyNOPRMTV3pvyFR30mr449+JQWO8D1D1Jr0u627fpVyPihu37JT0h6YykL+vgqoi9edcJTKpVAQwATdKqIQgAaBICGACSEMAAkIQABoAkBDAAJJlqSaLl5eVYXV198+v9/X0tLdV/jasm17m7u3u76tUS+tHG1apDG6NGImLix9raWvTb3t6OJmhynZJ2Yoo2KvqgjatVhzbmUZ8HQxAAkKTQqsgv/ssdbY5YIXTv8Y8W+fGoAdoYqA49YABIQgADQBICGACSEMAAkIQABoAkBDAAJCGAASAJAQwASQhgAEhCAANAEgIYAJIQwACQhAAGgCQEMAAkIYABIEmh+YDRDrYvSrooSSsrK+p0Om9uWzkpXT53d+j39r82U7fbrU0tozSlTswHAQxFxHVJ1yVpfX09NjY23tz2qRt/qWsvDv812buwMXTbPHU6HfXXXVdNqRPzwRAEACQhgAEgCQEMAEkIYABIQgADQJKxV0FwidL8NKVOAOUYG8BcojQ/TakTQDkYggCAJAQwACQhgAEgCQEMAEkIYABIQgADQBICGACSEMAAkIT5gIESrV55duT2rfNLc6oETUAPGACSEMAAkIQABoAkjAGDGe9KNOr/SqpPnagHAhjMeFeizQk+hKtDnagHhiAAIAkBDABJCGAASEIAA0ASAhgAkhDAAJCEAAaAJAQwACThRow5YqYsAP3oAQNAEgIYAJIQwACQhAAGgCQEMAAkIYABIAkBDABJCGAASEIAA0ASR8ToF/StFybprKSX+jYvS7pdTWmlanKdZyLi3ip3ShvPVUobo57GBvDIb7Z3ImK9xHoqQZ2zq2NNg1AnmoghCABIQgADQJKiAXy9lCqqR52zq2NNg1AnGqfQGDAAYHYMQQBAEgIYAJIQwACQhAAGgCQEMAAk+T8bsSn/I66i4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, we will create a histogram for all the numeric variables.\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "num_ix = dataframe.select_dtypes(include=['int64','float64']).columns\n",
    "subset=dataframe[num_ix]\n",
    "ax=subset.hist()\n",
    "for axis in ax.flatten():\n",
    "    axis.set_xticklabels([])\n",
    "    axis.set_yticklabels([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see that most of the variables have different distributions such as gaussian, exponential etc.\n",
    "### For better results we will scale the data.\n",
    "### Now we will split the data into input and output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ix =len(dataframe.columns)-1\n",
    "\n",
    "X,y = dataframe.drop(last_ix,axis=1),dataframe[last_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do one-hot-encoding on the categorical variables  columns.\n",
    "# selectin the categorical values.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cat_ix = X.select_dtypes(include=['object','bool']).columns\n",
    "ct = ColumnTransformer([('o',OneHotEncoder(),cat_ix)],remainder='passthrough')\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-10-d4457237a42f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-d4457237a42f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    return X,y\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y =LabelEncoder().fit_transform(y)\n",
    "return X,y\n",
    "## Why did we not use one-got encoder here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will be creating a function where we will define the F2 metric so that we can define the metric to evaluate the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_measure(y_true,y_pred):\n",
    "    return fbeta_score(y_true,y_pred,beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function where we evaluate a given model on the given folds and analyze the performance of the folds on the basis of F2 measures.\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_model(X,y,model):\n",
    "    cv=RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "    metric=make_scorer(f2_measure)\n",
    "    scores=cross_val_score(model,X,y,scoring=metric,cv=cv,n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use the the above test harness for baseline predictions.\n",
    "## The model which will predict the minority class for the examples will have a high recall score.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "model=DummyClassifier(strategy='constant',constant=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F2: 0.682 (0.000)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "scores=evaluate_model(X,y,model)\n",
    "print('Mean F2: %.3f (%.3f)' % (mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have a test harness and a baseline for performance so now we can spot check the algorithms that can help us further our cause.\n",
    "## We will be using the algorithms with the default parameters, not the tuned ones.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "def get_models():\n",
    "    models,names=list(),list()\n",
    "    models.append(LogisticRegression(solver='liblinear'))\n",
    "    names.append(\"LR\")\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append(\"LDA\")\n",
    "    models.append(GaussianNB())\n",
    "    names.append(\"NB\")\n",
    "    models.append(GaussianProcessClassifier())\n",
    "    names.append('GPC')\n",
    "    models.append(SVC(gamma='scale'))\n",
    "    names.append('SVM')\n",
    "    return models,names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will evaluate each model separately and store the scores to be evaluated later.\n",
    "#### But first we will be transforming the data, the categorical input variables will be one -hot encoded and the numerical values will be scaled using the min-max scaler on every cross-validation set.\n",
    "#### We will be using the pipeline for transforming the data  and updating the theloaddataset function for updating the numerical input variables as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    dataframe = read_csv(filename,header=None)\n",
    "    last_ix = len(dataframe.columns)-1\n",
    "    X,y = dataframe.drop(last_ix,axis=1),dataframe[last_ix]\n",
    "    cat_ix=X.select_dtypes(include=['object','bool']).columns\n",
    "    num_ix = X.select_dtypes(include=['int64','float64']).columns\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X.values, y, cat_ix, num_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,cat_ix,num_ix = load_dataset(filename)\n",
    "models,names = get_models()\n",
    "results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    ct=ColumnTransformer([('c',OneHotEncoder(),cat_ix),('n',MinMaxScaler(),num_ix)])\n",
    "    pipeline = Pipeline(steps=[('t',ct),('m',models[i])])\n",
    "    scores = evaluate_model(X,y,pipeline)\n",
    "    results.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we compare the algorithms using the F2 measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">SVM 0.436 (0.077)\n"
     ]
    }
   ],
   "source": [
    "# Now we will be directly comparing the means of the F2 scores for the algorithms.\n",
    "print('>%s %.3f (%.3f)' % (names[i],mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "pyplot.boxplot(results,labels=names,showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we already knew that the dataset we are dealing with here are a case of imbalanced dataset. We will be using undersampling techniques for solving this issue.\n",
    "### Undersampling methods are rarely used for addressing imbalanced data. Undersampling helps remove those data instances which may increase the accuracy of a classification algorithm.\n",
    "\n",
    "#### For the undersampling experiment we will be using the following undersampling techniques.\n",
    "* Tomek Links\n",
    "* Edited Nearest Neighbors\n",
    "* Repeated Edited Nearest Neighbors\n",
    "* One sided Selection\n",
    "* Neighborhood Cleaning Rule\n",
    "\n",
    "* The TOMEK and ENN methods can be used for selecting which instances of the dataset need to be deleted.\n",
    "* The OSS and NCR models can be used for selecting the examples which both need to be kept and deleted.\n",
    "* We will check all the undersampling algorithms with the logistic regression algorithm.\n",
    " \n",
    " \n",
    "* We will update the get model function accordingly so that the undersampling methods can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will edit the get_models.\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "def get_models():\n",
    "    models,names = list(),list()\n",
    "    models.append(TomekLinks())\n",
    "    names.append('TL')\n",
    "    models.append(EditedNearestNeighbours())\n",
    "    names.append('ENN')\n",
    "    models.append(RepeatedEditedNearestNeighbours())\n",
    "    names.append('RENN')\n",
    "    models.append(OneSidedSelection())\n",
    "    names.append('OSS')\n",
    "    models.append(NeighbourhoodCleaningRule())\n",
    "    names.append('NCR')\n",
    "    return models, names\n",
    "X, y, cat_ix, num_ix = load_dataset(filename)\n",
    "models,names = get_models()\n",
    "results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we are using undersampling methods we cannot use the scikit learn pipeline for analyzing our undersampling methods.\n",
    "### We will be using the pipeline provided by the  imblearn library.\n",
    "### The first step would be to one hot encode the categorical variables and normalization of the numerical variables, then we will use the undersampling techniques and then we will fit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">TL 0.669 (0.057)\n",
      ">ENN 0.706 (0.048)\n",
      ">RENN 0.714 (0.041)\n",
      ">OSS 0.669 (0.057)\n",
      ">NCR 0.693 (0.052)\n"
     ]
    }
   ],
   "source": [
    "# Creating the results for the undersampling models.\n",
    "for i in range (len(models)):\n",
    "    model =LogisticRegression(solver='liblinear',class_weight='balanced')\n",
    "    ct=ColumnTransformer([('c',OneHotEncoder(),cat_ix),('n',MinMaxScaler(),num_ix)])\n",
    "    pipeline = Pipeline(steps=[('t',ct),('s',models[i]),('m',model)])\n",
    "    scores = evaluate_model(X,y,pipeline)\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (names[i],mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the performances of the visually.\n",
    "pyplot.boxplot(results,labels=names,showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see that the overall performance of the model was boosted.\n",
    "#### We will use the RENN model as it was the highest performing model.\n",
    "#### We will fit the complete data to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('t',\n",
       "                 ColumnTransformer(transformers=[('c', OneHotEncoder(),\n",
       "                                                  Int64Index([0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19], dtype='int64')),\n",
       "                                                 ('n', MinMaxScaler(),\n",
       "                                                  Int64Index([1, 4, 7, 10, 12, 15, 17], dtype='int64'))])),\n",
       "                ('s', NeighbourhoodCleaningRule()),\n",
       "                ('m',\n",
       "                 LogisticRegression(class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the model has been fitted, we can make predictions for the new data by calling the predict() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
